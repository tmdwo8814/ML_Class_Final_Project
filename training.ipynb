{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments on Effective Data Augmentation Techniques - Lung Cancer Type Classification Problem\n",
    "\n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SJ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\SJ\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from model_CNN import cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './data/train/'\n",
    "val_path = './data/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.ImageFolder(train_path, transform=transform_train)\n",
    "val_set = datasets.ImageFolder(val_path, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=8, num_workers=4, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set, batch_size=8, num_workers=4, shuffle=True)\n",
    "loaders = {\n",
    "    'train' : train_loader,\n",
    "    'valid' : val_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {\n",
    "    'train' : 465, \n",
    "    'valid' : 59\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import Variable\n",
    "\n",
    "# def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "#     '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "#     if alpha > 0:\n",
    "#         lam = np.random.beta(alpha, alpha)\n",
    "#     else:\n",
    "#         lam = 1\n",
    "\n",
    "#     batch_size = x.size()[0]\n",
    "#     if use_cuda:\n",
    "#         index = torch.randperm(batch_size).cuda()\n",
    "#     else:\n",
    "#         index = torch.randperm(batch_size)\n",
    "\n",
    "#     mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "#     y_a, y_b = y, y[index]\n",
    "#     return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "# def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "#     return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mixup ver\n",
    "# def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "#     best_loss = float('inf')\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "#         print('-' * 10)\n",
    "\n",
    "#         for phase in ['train', 'valid']:\n",
    "#             if phase == 'train':\n",
    "#                 model.train()\n",
    "#             else:\n",
    "#                 model.eval()\n",
    "\n",
    "#             running_loss = 0.0\n",
    "#             running_corrects = 0\n",
    "\n",
    "#             for inputs, labels in loaders[phase]:\n",
    "#                 inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#                 # mixup 적용\n",
    "#                 inputs, targets_a, targets_b, lam = mixup_data(inputs, labels,\n",
    "#                                                                1.0, True)\n",
    "#                 inputs, targets_a, targets_b = map(Variable, (inputs,\n",
    "#                                                               targets_a, targets_b))\n",
    "#                 # /mixup 적용\n",
    "#                 optimizer.zero_grad()\n",
    "\n",
    "#                 with torch.set_grad_enabled(phase == 'train'):\n",
    "#                     outputs = model(inputs)\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "#                     loss = criterion(outputs, labels)\n",
    "\n",
    "#                     if phase == 'train':\n",
    "#                         loss.backward()\n",
    "#                         optimizer.step()\n",
    "\n",
    "#                 running_loss += loss.item() * inputs.size(0)\n",
    "#                 running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "#             epoch_loss = running_loss / dataset_sizes[phase]\n",
    "#             epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "#             if phase == 'valid' and best_loss > epoch_loss:\n",
    "#                 best_loss = epoch_loss\n",
    "#                 torch.save(model.state_dict(), './weight/model.pth')\n",
    "\n",
    "\n",
    "#             print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in loaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            if phase == 'valid' and best_loss > epoch_loss:\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(model.state_dict(), './weight/model.pth')\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=44944, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = cnn().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.0191 Acc: 0.4989\n",
      "valid Loss: 1.1221 Acc: 0.3559\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.8624 Acc: 0.5570\n",
      "valid Loss: 0.9459 Acc: 0.5593\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.7096 Acc: 0.6968\n",
      "valid Loss: 1.0628 Acc: 0.6271\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.5366 Acc: 0.7914\n",
      "valid Loss: 1.2361 Acc: 0.5763\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.5038 Acc: 0.7892\n",
      "valid Loss: 1.0060 Acc: 0.5424\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.4307 Acc: 0.8344\n",
      "valid Loss: 0.7888 Acc: 0.6441\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.3103 Acc: 0.9075\n",
      "valid Loss: 0.5382 Acc: 0.7458\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.2230 Acc: 0.9204\n",
      "valid Loss: 0.6673 Acc: 0.6949\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.1583 Acc: 0.9570\n",
      "valid Loss: 0.8134 Acc: 0.7627\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.2432 Acc: 0.9054\n",
      "valid Loss: 0.7519 Acc: 0.6780\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, criterion, optimizer,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    accuracy = corrects.double() / total\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5096\n"
     ]
    }
   ],
   "source": [
    "test_set = datasets.ImageFolder('./data/test/', transform=transform_val)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=8, shuffle=False, num_workers=4)\n",
    "test_model(trained_model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbba352725f312b06156d25d0e4c4846f04beb985608aefa695f1718f92fb570"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
